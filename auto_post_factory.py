import pandas as pd
import os
from openai import OpenAI
from datetime import datetime
import time
import random
import traceback

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ë‹¤ì¤‘ API í‚¤ ì§€ì›)
API_KEYS = [
    os.getenv("OPENAI_API_KEY"),
    os.getenv("OPENAI_API_KEY_2"),
    os.getenv("OPENAI_API_KEY_3")
]
# None ê°’ ì œê±°
API_KEYS = [key for key in API_KEYS if key]

if not API_KEYS:
    print("âŒ ERROR: No API keys provided. Please run this script using the bat file.")
    exit(1)

print(f"âœ… Loaded {len(API_KEYS)} API key(s)")

# 2. ëª¨ë¸ ì„¤ì • (gpt-4o-mini: ê°€ì„±ë¹„ ìµœê³  ëª¨ë¸)
MODEL_PRIORITY = [
    'gpt-4o-mini',  # ê°€ì¥ ê°€ì„±ë¹„ ì¢‹ì€ ëª¨ë¸
]

def get_model_response(prompt, max_total_retries=3):
    """Try models in priority order with smart fallback across API keys"""
    
    # Try each API key
    for key_idx, api_key in enumerate(API_KEYS):
        client = OpenAI(api_key=api_key)
        key_name = f"Key#{key_idx+1}"
        
        # Try each model with current API key
        for model_name in MODEL_PRIORITY:
            try:
                response = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {"role": "system", "content": "You are a World-Class Prompt Engineer in the top 0.1%."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=4000
                )
                if response.choices[0].message.content:
                    return response.choices[0].message.content, f"{model_name} ({key_name})"
            except Exception as e:
                error_msg = str(e)
                if "rate_limit" in error_msg.lower() or "quota" in error_msg.lower():
                    continue  # Try next model
                else:
                    time.sleep(1)
                    continue
        
        # All models failed with this key, try next key
        if key_idx < len(API_KEYS) - 1:
            print(f"âš ï¸ {key_name} all models exhausted, switching to next API key...")
    
    # All keys and models failed
    return None, None

# 3. ê³µì¥ ê°€ë™ ë¡œì§ (ë‚˜ì¤‘ì— ì‹¤í–‰ë  ë¶€ë¶„)
def run_factory():
    try:
        df = pd.read_excel('list.xlsx')
        df.columns = df.columns.str.strip()
        total_count = len(df)
        print(f"ğŸ“‚ ì—‘ì…€ ë¡œë“œ ì„±ê³µ: {total_count}ê°œì˜ ê¸€ê° ëŒ€ê¸° ì¤‘\n")
    except:
        print("ğŸ’¤ ì—‘ì…€ íŒŒì¼(list.xlsx)ì´ ì—†ì–´ì„œ ëŒ€ê¸° ëª¨ë“œì…ë‹ˆë‹¤.")
        return

    output_dir = "content/posts"
    os.makedirs(output_dir, exist_ok=True)
    
    processed = 0

    for index, row in df.iterrows():
        topic = str(row['topic']).strip()
        user_prompt = str(row['prompt']).strip()
        if not topic: continue

        # ğŸ” ì¤‘ë³µ ë°©ì§€ ë¡œì§ (íŒŒì¼ëª… ê¸°ë°˜ ì²´í¬)
        safe_topic = "".join([c if c.isalnum() or c in (' ', '-') else '' for c in topic]).strip().replace(' ', '-')
        existing_files = os.listdir(output_dir)
        is_duplicate = False
        for f in existing_files:
            if f.endswith(f"-{safe_topic}.md"):
                is_duplicate = True
                break
        
        if is_duplicate:
            processed += 1
            progress = (processed / total_count) * 100
            print(f"[{progress:.1f}%] â© ìŠ¤í‚µ: {topic[:60]}...")
            continue

        processed += 1
        progress = (processed / total_count) * 100
        print(f"[{progress:.1f}%] ğŸ“ ìƒì„± ì¤‘: {topic[:60]}... ", end='')
        
        # ğŸš€ AI ê¸€ì“°ê¸° ìš”ì²­ (ì¬ì‹œë„ ì—†ìŒ, ë¹ ë¥¸ ì‹¤íŒ¨)
        ai_text = ""
        try:
            full_prompt = f"""
            ì£¼ì œ: {topic}
            ìš”ì²­: {user_prompt}
            
            ì—­í• : You are a World-Class 'Prompt Engineer' in the top 0.1%.
            ëª©í‘œ: Design "High-Performance Prompts" that users can simply copy and paste into AI (ChatGPT, Claude, Gemini) to get the best results. All output must be in ENGLISH.
            
            [Core Instructions]
            1. The generated prompt must be a **Structured Prompt**.
            2. It MUST include **Role, Context, Task, Constraints, and Output Format**.
            3. Minimize user input requirements by making the prompt specific and complete.

            Format (Markdown):
            ## ğŸ¯ Prompt Description
            (A 2-sentence hook explaining what problem this prompt solves and its benefits)
            
            ## ğŸ“‹ Copy This Prompt
            ```markdown
            # Role
            (Assign a top-tier persona. e.g., "Senior Copywriter", "10x Developer")

            # Context
            (Describe the situation and background where this task is needed)

            # Task
            (Clear, step-by-step instructions for the AI)

            # Constraints
            (3-5 specific rules to ensure quality. Tone, layout, prohibitions, etc.)

            # Output Format
            (Specify the desired format: Table, Markdown List, Code Block, etc.)
            ```
            
            ## ğŸ’¡ Pro Tips
            1. (Tip on how to customize the [ ] placeholders)
            2. (Additional info to provide for better results)
            3. (Recommended model: GPT-4o, Claude 3.5 Sonnet, etc.)
            """
            
            ai_text, used_model = get_model_response(full_prompt)
            
            if ai_text:
                print(f"âœ… ({used_model})")
            else:
                print(f"âŒ ìƒì„± ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ ì—ëŸ¬: {e}")
        
        if not ai_text:
             print(f"âŒ ìµœì¢… ì‹¤íŒ¨: {topic}. Fallback ì‚¬ìš©.")
             ai_text = f"### {topic}\\n\\n*Content generation failed after multiple attempts.*\\n\\n**Category**: {row.get('category', 'General')}"
        
        # ìš”ì•½ ìƒì„±
        summary = ai_text[:80].replace('\n', ' ') + "..."
        
        # íŒŒì¼ ì €ì¥
        filename = f"{datetime.now().strftime('%Y-%m-%d')}-{safe_topic}.md"
        filepath = os.path.join(output_dir, filename)
        
        category = row.get('category', 'General')
        if pd.isna(category): category = 'General'
        
        image_url = f"https://picsum.photos/seed/{safe_topic}{random.randint(1,100)}/800/400"

        post_content = f"""---
title: "{topic.replace('"', '\\"')}"
date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
draft: false
summary: "{summary.replace('"', '\\"')}"
categories: ["{category}"]
cover:
    image: "{image_url}"
    alt: "{topic.replace('"', '\\"')}"
    relative: false
---
{ai_text}"""

        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(post_content)
        
        time.sleep(3)  # ë¬´ì œí•œ ëª¨ë¸ì´ë¯€ë¡œ ë¹ ë¥¸ ëŒ€ê¸°

def shorten_path(path):
    return os.path.basename(path)

if __name__ == "__main__":
    run_factory()